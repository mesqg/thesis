\chapter{STLC and System F}
\label{cha:2}
Programming languages should have desirable properties we can take advantage of when using them. But before relying on those properties, they should be rigorously proved. For that, it is very useful to have a small core language (to minimize what we need to take into account when proving such results), capable of expressing the full power of the language. This chapter is based on Chapters $5,6,9$ and $23$ of Types and Programming Languages \cite{tapl}.

\section{The Untyped Lambda-Calculus}
The (untyped) lambda-calculus, introduced in the 1920s by Alonzo Church, is one such (very) small core language, based on the essential notion of functions. Functions are expressions abstracted over some variables; and can be given arguments to replace these variables. This yields a new expression which may (or may not) then be further evaluated.

In the pure lambda-calculus, functions are called abstractions (even though throughout this thesis we use functions and abstractions interchangeably). Whereas functions usually use the notation \texttt{f(x)= some expression using x}, we use the lambda notation: $\lambda \tyVar . some\;expression\;using\; \tyVar$; another difference is that while applying a function to a given argument is usually written as \texttt{f(argument)}, we write $(\lambda \tmVar . some\; expression\; using\;\tmVar) \; argument$. Lambda-calculus' terms can only be variables ($\tmVar$), abstractions of some term over a variable ($\lambda \tmVar. \term$) or the application of a term to another: $\term_1$ $\term_2$. This is reflected by \fref{untypedsyntax}, where the vertical bars can be read as ``or''. In $\lambda \tmVar. \term$, we sometimes refer to $\term$ as the body of the abstraction.

\begin{figure}
  \centering
  $\term ::= \tmVar\,|\,\lambda \tmVar:\type.\term\,|\,\term_1 \; \term_2  \hfill terms $\\
  \caption{Syntax for the untyped lambda-calculus}
  \label{untypedsyntax}
\end{figure}
Abstractions can be nested: $\lambda \tmVar_1. \lambda \tmVar_2 .\tmVar_1$ is a valid term that, when applied to one argument and then a second, it returns the first. However, had we written it as $\lambda \tmVar. \lambda \tmVar. \tmVar$, we wouldn't know which argument to return. We say that the $\tmVar$ in the inner abstraction is shadowing the $\tmVar$ in the outer. This is easily solved with De Bruijn's indices: give numbers to variables that reflect to which $\lambda$ they refer. That same term would translate into $\lambda .\lambda.1$. You can think of this term as $\lambda 1.\lambda 0.1$. More information on De Bruijn's indices can be found on chapter 6 of Types and Programming Languages\cite{tapl}.

The important point to retain is that the names given to the variables can easily become a non-issue. This notions that the names of the variables are irrelevant for the meaning of the term is called $\alpha$ conversion.

In case we enrich the calculus with naturals and addition, we can write terms such as $(\lambda \tmVar_2.\tmVar_2 + 1)\,15$ (applying $15$ to the successor function) or more convoluted terms like $((\lambda \tmVar_1. \lambda \tmVar_2 .3 + (\tmVar_1\;\tmVar_2)\;) \, (\lambda \tmVar_3.\tmVar_3 + 1))\,15$, which would simplify to $3+(15+1)$. Despite its interest, its simple syntax and evaluation rules also allow for meaningless terms (non-values for which no evaluation rules exist) such as $\tmVar_1 \, \tmVar_2$ or $\tmVar_1 \, (\lambda \tmVar_2.5)$.

\section{Simply Typed Lambda Calculus}
In order to solve this problem, types were introduced, resulting in the simply typed lambda-calculus (STLC). Types will ensure that certain terms (called \textit{well-typed} terms) share some highly desirable properties. Erroneous code will not be well-typed (although well-typedness is not a guarantee of the behavior the programmer intended) and as such we will know about these errors at compile time rather than at runtime.
\subsection{Syntax}
\begin{figure}
  %\centering
  $\term ::= \tmVar\,|\,\lambda \tmVar:\type.\term\,|\,\term_1 \; \term_2 \,|\, \highlight{\{0,1,...\}} \hfill terms $\\
  $\highlight{\tmVal::= \lambda \tmVar:\type.\term \,|\, \{0,1,...\}} \hfill \highlight{values}$\\
  $\highlight{\type ::= \type \rightarrow \type \,|\,\Nat} \hfill \highlight{types}$\\
  $\highlight{\tyEnv::=  empty \,|\, tyEnv, \tmVar:\type} \hfill \highlight{environment}$\\
    \caption{STLC's syntax (extended with Naturals)}
  \label{STLC syntax}
\end{figure}

The syntax of the (pure) STLC is illustrated in \fref{STLC syntax}. We highlight new syntax in grey. As in its untyped counterpart, terms can be either a variable ($\tmVar$); the abstraction of another term over some variable ($\lambda \tmVar : \type . \term$); or the application of one term to another ($\term_1 \; \term_2$). New here is the notion of value, a special term. In the STLC, we define as values all abstractions and nothing else. Extensions of the STLC introduce new syntax, some of which may be defined to be values as well.

Abstractions now require the type of its argument to be explicitly given (in an annotation immediately after the variable). Having this requisite qualifies a language as explicitly typed.

To make STLC interesting, we need to introduce some base type to it. Otherwise, no term would be well-typed (we'll get back to this shortly). We'll extend the pure STLC with natural numbers. In this extension, natural numbers are considered values too (which implies they are also terms).

\subsection{Typing}
It is the combination of the typing rules with the evaluation rules that ensures that in STLC well-typed terms never reach a state in which they are neither a value nor can continue evaluating. We call this property type safety.

In type safe languages, saying that a term $\term$ has type $\type$ means that no values of a type other than $\type$ will result from its evaluation. It's stronger than that: either the evaluation goes on forever, or we get a value of the given type.

Types reflect the fundamental difference between abstractions (a mathematical function) and other terms. Abstractions are given a \textit{function type} ($\type_1 \rightarrow \type_2$). These inform about the type of the argument the abstraction can be applied to ($\type_1$) and about the resulting type of that operation, $\type_2$. In our extension, we have added the \textit{base type} $\Nat$ and decide to give it to natural numbers. A \textit{base type} is a type that is not constructed from other types. This is opposed to \textit{function types}, which are constructed from two types: the type of the argument and the type of the result. If there are no base types, there are no types at all and no term can ever have a type.

\textit{Well-typed} terms are defined as being the terms we can give some type to (we'll call the remaining terms \textit{ill-typed}). To avoid proving the desirable properties of well typed terms to be completely useless, we need a base type.

The typing rules for this extended STLC (the combination of the pure STLC's typing rules and the ones we introduced for natural numbers) reflect our choice to give natural numbers the type $Nat$. This means that natural numbers are well-typed terms. Infinitely many other terms are also well-typed. This will be clear once we take a closer look at the rules.

Using our intuition that types classify what terms are, we expect the type of the identity function applied to a natural number $((\lambda \tmVar: Nat \rightarrow Nat. \tmVar) \, 4)$ to be $Nat$. Likewise, we expect the type of the function $\lambda \tmVar:Nat.\tmVar+3$ to be $Nat \rightarrow Nat$.

The typing rules are intuitive if we keep in mind the behavior of functions: applying a function that takes elements of a set $X$ to elements of $Y$ to an argument from $X$ results in an element of $Y$. Conversely, if by assuming the argument given to the function is in some set $X$ we can be sure it will return an element of $Y$, then we can call it a function from $X$ to $Y$. Indeed, a given abstraction could have several types if it was not explicitly annotated.

Because abstractions can be nested, we must keep track of all assumptions made about the types of variables. We keep them in what we call an environment (we use $\tyEnv$ for environments). Therefore, typing is a relation in the product of environments, terms and types. We show the typing rules in \fref{STLC typing}.

The T-Var rule simply states that, if we assumed some variable to have a given type, then, under our assumptions, that variable has that given type. The rules T-Abs and T-App reflect our intuition about functions (or abstractions, in STLC terminology). Note that $\tyEnv,\tmVar:\type_1$ in the rule T-Abs represents the environment $\tyEnv$ to which the assumption ``$\tmVar$ has type $\tyVar$'' has been added.

\begin{figure}
  \centering
  \includegraphics{typingrules}
  \caption{Typing rules for STLC}
  \label{STLC typing}
\end{figure}
\subsubsection{Typing derivations}
A typing derivation is a constructive proof that some term $\term$ as a given type $\type$. It shows how to use the typing rules to infer that conclusion. In a typing derivation for a STLC's term, we'll usually start with $\tyEnv=empty$, i.e., we start with no assumptions. Note that the $\tyEnv$ in the typing rules hold for any environment, in particular to the $empty$ environment.

In STLC, a well-typed term has exactly one type (ill-typed have none), and it can be proven that the typing derivations are unique: there is exactly one way to prove a term has its type.

\subsubsection{Example of a typing derivation}
\fref{stlctydev} shows an example of a typing derivation for $((\lambda \tmVar: \Nat \rightarrow \Nat.3) \, (\lambda \tmVar:\Nat.\tmVar))\,15)$. We prove that it has type $\Nat$.

The easiest way to understand it is from bottom to top. Because our term is an application we look for the rule T-App. To prove our term has type $\Nat$ we now know that we need to prove that, for some $\type$, $((\lambda \tmVar: \Nat \rightarrow \Nat.3) \, (\lambda \tmVar:\Nat.\tmVar))$ has type $\type \rightarrow \Nat$ and that $15$ as type $\type$. We stick to this approach and keep simplifying what we need to prove until we reach a trivial case. By trivial cases we mean either we reach a typing rule with no premises (T-NatZero) or a true statement (using T-Var).

Note that if we tried to prove our term had type $\Nat \rightarrow \Nat$, we would reach a point in which no typing rules would apply, so our derivation would be incomplete and thus not a proof.

\begin{figure}
  \centering
  \includegraphics[angle=90,height=21cm]{stlctdev}
  \caption[angle=90]{Typing Derivation for  $((\lambda \tmVar: \Nat \rightarrow \Nat.3) \, (\lambda \tmVar:\Nat.\tmVar))\,15)$}
  \label{stlctydev}
\end{figure}

\subsection{Evaluation}
Given that STLC is a language with only variables, abstractions, and applications, it is no surprise that evaluation steps only happen in the presence of applications. In particular, in an application in which the left side is an abstraction. If we have a pair of a function from $\tyVar_1$ to $\tyVar_2$ and an argument of type $\tyVar_1$, we know what to do: replace that variable in the body of the function by the argument given. Then, either we choose to stop; or we look again for one such pair. We call a pair of a functions and a fitting argument a reducible expression, or redex for short. We wouldn't know how to further evaluate anything other than redexes.

\begin{figure}
  \centering
  \includegraphics{stlcevalrules}
  \caption{Evaluation rules for STLC}
  \label{STLC eval}
\end{figure}

Happiness is defined in different ways by different people and this applies to evaluating STLC terms as well: there are several ways to define the evaluation rules. This is the same as to say there are several ways to decide which redexes get evaluated first and even if they get evaluated at all. We'll present the evaluation rules of call-by-name: this is Haskell's strategy, except for the fact that Haskell memorizes which terms are the same in order to avoid computing the same multiple times (we name Haskell's evaluation strategy call-by-need).

The evaluation rules are presented in \fref{STLC eval}. The formula $[\term_2/\tmVar]\term_1$ represents $\term_1$ in which all occurrences of the variable $\tmVar$ were replaced by the term $\term_2$.

Being the rules for a functional language, it seems fitting that we choose to stop whenever we get a function: evaluation stops when we get to an abstraction not in a redex. In other words, we cannot evaluate redexes inside the body of an abstraction, because none of the evaluation rules can then be applied. The rule E-App states that if we can further evaluate the left side of an application, the whole application evaluates to the new left side applied to the same right side. In a way, this evaluation strategy looks ahead to figure out what will happen with the argument when it is part of a redex. If it turns out the argument is never used, it is never evaluated. For this reason, call-by-name (and Haskell's call-by-need) are said to be lazy evaluation strategies.

In most of the traditional programming languages, the arguments must always be evaluated: this is called a strict or eager evaluation strategy. One example of such evaluation strategy is call-by-value. In call-by-value, only the outermost redex for which the right side is already a value can be further evaluated.
\subsubsection{An example of a call-by-name evaluation of a term}
In \fref{stlcexeval} (where $N$ represents $\Nat$ for brevity), we show how the evaluation of a non-trivial STLC's term proceeds. Keep in mind that evaluating a term means replacing it,\textit{i.e.} replacing the top-level expression, by some other term.

First, we note we can further evaluate the left side of the application: we can apply E-AppAbs to $(\lambda \tmVar_1: (N \rightarrow N)\rightarrow N.\lambda \tmVar_2:N.\lambda \tmVar_3: N . (\tmVar_1 \, \tmVar_2)\,\tmVar_3) (\lambda \tmVar_4:N. \lambda \tmVar_5:N. \tmVar_4 + \tmVar_5)$, by replacing $\tmVar_1$ everywhere in $\lambda \tmVar_2:N.\lambda \tmVar_3: N . (\tmVar_1 \, \tmVar_2)\,\tmVar_3$ by $\lambda \tmVar_4:N. \lambda \tmVar_5:N. \tmVar_4 + \tmVar_5$. The rule E-App then allows us to replace our old top-level expression by one in which the left side has been evaluated.

We then apply E-AppAbs to what is now a simple redex. As such, we replace the variable $\tmVar_2$ everywhere in the body of the abstraction by the number $3$. We then stop because no evaluation rules apply to the top-level expression.

Note how the redex $(\lambda \tmVar_4:N. \lambda \tmVar_5:N. \tmVar_4 + \tmVar_5) \, 3$ is not further simplified due to being within a lambda abstraction.
\begin{figure}
  \centering
  $((\lambda \tmVar_1: (N \rightarrow N)\rightarrow N.\lambda \tmVar_2:N.\lambda \tmVar_3: N . (\tmVar_1 \, \tmVar_2)\,\tmVar_3) (\lambda \tmVar_4:N. \lambda \tmVar_5:N. \tmVar_4 + \tmVar_5)) 3$\\
$\rightarrow_{E-AppAbs followed by E-App}(\lambda \tmVar_2:N.\lambda \tmVar_3: N. ((\lambda \tmVar_4:N. \lambda \tmVar_5:N. \tmVar_4 + \tmVar_5) \, \tmVar_2)\,\tmVar_3) 3 $\\
$\rightarrow_{E-AppAbs} \lambda \tmVar_3: N. ((\lambda \tmVar_4:N. \lambda \tmVar_5:N. \tmVar_4 + \tmVar_5) \, 3)\,\tmVar_3 $
  \caption{Example of an evaluation of a STLC's term}
  \label{stlcexeval}
\end{figure}

\section{System F}
In the pure lambda-calculus, we could write the abstraction ``$id=\lambda\tmVar.\tmVar$'' which, when applied to a term, returns it. Functions in untyped lambda calculus don't care about their argument: they are defined for any and behave the same for all of them. This behavior is close to what we would call, in a slightly more evolved setting where we would have types, parametric polymorphism. Parametric polymorphism is defined (\cite{adhoc}) as occurring ``when a function is defined over a range of types, acting in the same way for each type''.

In STLC, we cannot write one single identity function and have it defined over a range of types: because the lambda abstractions are type annotated, we need a different function for each type. Applying an abstraction $\lambda \tmVar : \type_1$ to a term $\term$ of type $\type_2$ is not well-typed and thus not part of the language. The same holds for any other function: it can be defined for only one type. It is clear that the lack of parametric polymorphism is a severe limitation of STLC.

System F extends STLC with parametric polymorphism while maintaining the type safety found in STLC.

\subsection{Syntax}
We want to be able to abstract terms over types, so that we can write functions that apply over a range of types. For this purpose, we need to add type variables and a language construct $\Lambda \type.\term$ that represents the abstraction of $\term$ over the type variable $\type$. We can now re-write $id$ as $\Lambda \type. \lambda \tmVar_1: \type . \tmVar_1$. Terms of the form $\Lambda \type.\term$ are called type abstractions. Because the newly defined $id$ is, in essence, still a function, we want to consider it a value. We define type abstractions to be values too.

We then need to be able to apply a type $\type$ to such a term in order to have a ``normal'' function we can apply to arguments of type $\type$. This way, the syntax is further extended to include the application of a type to a term. If we then apply the type $\Nat$ to our new $id$ function, we get a function that a has type $\Nat \rightarrow \Nat$. This is completely analogous to term application: we call it type application. Note that in System F there is no way to constrain type we apply in a type application.

System F's syntax is shown is \fref{sysfsyntax}; it is an extension of STLC's.

\begin{figure}
    $\term ::= \tmVar\,|\,\lambda \tmVar:\type.\term\,|\,\term_1 \; \term_2 \,|\,\Lambda \tyVar .\term\,|\,\term\;\type \hfill terms $\\
  $\tmVal::= \lambda \tmVar:\type.\term \,|\, \Lambda \tyVar. \term\hfill values$\\
  $\type ::= \tyVar\,|\,\type \rightarrow \type \,|\,\forall \tyVar.\type$\\
  $\tyEnv::=  empty \,|\, \tyEnv, \tmVar:\type\,|\, \tyEnv,\tyVar$\\
  \caption{Syntax for System F}
  \label{sysfsyntax}
\end{figure}

\subsection{Typing}
Drawing another parallelism with STLC, as before we stored the assumptions we made about the term variables and could only reason about variables in the environment; now we must also keep track of the the type variables we have encountered.

The typing environment can now be extended with type variables: ``$\tyEnv,\tyVar$''. We introduce type variables to the environment when type-checking type abstraction.

The same way a term can only be well-typed if all its variables are in the environment, types can only be \textit{well-formed} if all its type variables are in $\tyEnv$. This is actually the only condition for type well-formedness. Type well-formedness is a concept we will use for the typing rules in System F. We represent ``under the typing environment $\tyEnv$, the type $\type$ is well-formed by ``$\tyEnv \vdash_{ty} \type''$.

Unsurprisingly, the System F's typing rules extend STLC's. We add the \textsc{T-TApp} rule that types type application. If a term $\term$ has some type of the form $\tyAbs{\tyVar}{\type_1}$, then the application of $\type_2$ to $\term$ has type that results from substituting the type variable $\tyVar$ in $type_1$ in by $\type_2$. We also add a rule (\textsc{T-TAbs}) for type abstraction stating that if, by adding the type variable $\tyVar$ to the typing environment, we can type term $\term$ as having type $\type$; then, abstracting $\term$ over that type variable has type $\tyAbs{\tyVar}{\type}$. We present the complete typing rules for System F in \fref{sysfty}.

We can now write one function $twice$ (given a function and a term, applies the function to the term and them applies it again on the result of the first computation), applicable to any type of term, as $\Lambda \type. \lambda \tmVar_1: \type \rightarrow \type . \lambda \tmVar_2:\type. \tmVar_1 (\tmVar_1 \tmVar_2)$. The type of $twice$ is $\tyAbs{\tyVar}{((\tyVar \rightarrow \tyVar) \rightarrow \tyVar) \rightarrow \tyVar}$.

\begin{figure}
  \centering
  \includegraphics{sysfty}
  \caption{Typing rules for the pure System F}
  \label{sysfty}
\end{figure}
\subsection{Evaluation}
As for the operational semantics of System F, they too extend those of STLC. System F has the same E-App and E-AppAbs rules for term abstraction and application; it also has their type counterpart: rules E-TyApp and E-TyAppAbs. These are completely analogous. All of them are shown in \fref{sysfeval}.

\begin{figure}
  \centering
  \includegraphics{sysfeval}
  \caption{Operational semantics for pure System F}
  \label{sysfeval}
\end{figure}

\section{Hindley-Milner}
Writing type annotations is really not an enjoyable moment for any programmer who know what (s)he's doing. The Hindley-Milner type system (HM) is a language without them. Nonetheless, there is an algorithm that is capable of inferring the type of its expressions. We can translate any HM expression into System F. We call this translation an elaboration because we elaborate the expression by type-annotating the variables introduced in lambda abstractions so that it conforms to System F's syntax. The price to pay for type inference is that HM is not as expressive as System F.
\subsection{HM syntax}

HM is expressive enough to support parametric polymorphism, and elegant enough to HM drop type annotations. This allows us to simplify the syntax of HM's terms: there is no need for explicit type variables, type abstraction and type application. The result of this simplification is that, despite being quite different languages, HM's syntax for terms is the same as STLC's.

What in new in HM is the further specialization of types. Types can now be monotypes or polytypes. Monotypes are either type variables (type variables only ceased to be explicit in the syntax of the terms, we still need them) or function types; polytypes are either a monotype or a type abstraction. HM leverages this distinction in its typing rules to make sure no type abstractions appear in nested positions in well-typed terms.

Regarding the environment, it is almost the same as the one for System F extended with data types. Type constructors are bound to a System F term because their in general, its arguments may be methods, which may be polymorphic (thus having type abstractions) which results in neither a monotype nor polytype but rather a System F type.

The complete syntax is presented in \fref{hmsyntax}.

%Type variables are still present in the typing environment. The typing environment is very close to System F's, which is perhaps not surprising, considering  paramentric polymorphism. DATA CONSTRUCTORS ARE BOUND TO SYS F TYPE.


\begin{figure}
  \centering
    $\term ::= \tmVar\,|\,\lambda \tmVar.\term\,|\,\term_1 \; \term_2 \hfill terms $\\
  $\tmVal::= \lambda \tmVar:\type.\term \hfill values$\\
  $\type ::= \tyVar\,|\,\type \rightarrow \type \hfill monotypes$\\
  $\rho ::= \type \;|\;\forall \tyVar.\rho \hfill polytypes$\\
  $\tyEnv::=  empty \,|\, \tyEnv, \tmVar:\type\,|\, \tyEnv,\tyVar\,|\, \tyEnv, K : \sysftype \,|\, \tyEnv,T \hfill environment$\\
  \caption{HM's syntax}
  \label{hmsyntax}
\end{figure}

\subsection{Typing}
A HM type is said to be well-formed if all its type variables are in the typing environment. The typing rules (shown in \fref{hmtyrules}) are very similar to System F's, except that:
\begin{itemize}
\item Type annotations in the lambda abstractions are now gone.
\item In the counterparts to the rules regarding type abstraction and application in System F, the term in the premises and in the conclusion is the same. As if we simply ignored type abstraction over some term $\term$ and type application of some type $\type$ to term $\term$ and instead only consider that term $\term$.
\item Another different aspect is that the typing rules now assign polytypes to terms, instead of System F's more general types.
\end{itemize}
%\begin{figure}
 % \centering
  %\includegraphics{hmtyrules}
  %\caption{HM's typing rules}
  %\label{hmtyrules}
%\end{figure}

\subsection{Type inference}
HM assigns types to its well-typed terms in two separate steps: first it generates a set of equality constraints and a type (with unresolved type variables); then, the constraints are solved, a substitution is generated and applied to the previously inferred type, instantiating the necessary type variables. This algorithm assigns to each term its most general type.

%\subsubsection{Building up the constraints}
%\subsubsection{Solving the constraints and generating a substitution}

\section{System F extended}
We now extend System F with programs, making it closer to the language we'll use for our implicit type conversions and to a real world programming language. We recursively define a program as being either just a term; a value binding and a program; or a data type declaration and a program.

For our fore mentioned purpose, we need to re-design the syntax. We'll introduce let bindings, value binding, datatypes declarations, data constructors and case expressions. Instead of needing pre-defined base types as we did for the pure System F, we can now introduce them in our program through the use of data declarations.

Most of these additions to the pure System F's syntax make the language much more user-friendly but do not increase its expressive power. It'll be easy to see that we could just inline the value on a value binding to have the same effect, or use a redex to substitute everywhere the placeholder variable by the intended value. This is not obvious for datatypes (and for the data constructors and case expressions they introduce) but it has been shown they are encodable using polymorphism.

\subsection{Syntax}
As we can see from \fref{exsysfsyntax}, terms can now also be:
\begin{itemize}
\item Data constructors, denoted by $K$. These are functions that, when applied to terms of the correct type, construct a term of the type $T$ explicitly mentioned in the datatype declaration.
\item A \texttt{let}-expression that binds a (type annotated) variable $\tmVar$ to some expression $\term$. As we'll see from the typing rules (and from an example), the \texttt{let} we introduce here is the recursive let: it allows for the expression $\term$ to already refer to the variable $\tmVar$.
\item A \texttt{case}-expression. With these we are able to pattern match terms against their data constructor $K$ to retrieve information on the arguments provided to $K$.
\end{itemize}
We introduce the notion of program: a sequence of declarations and a term. The declarations can be either value bindings or datatype declarations.

The latter is the interesting case: they introduce a new type (this is a System F type, where type variables can be present) as well as a data constructor, which is the only way of constructing a term of that type.

The data and type constructors present in data declarations need to be stored somewhere, or the data declarations would be useless. As such, we extend the syntax of the typing environment to be able to handle such cases.

\begin{figure}
  $\highlight{pgm::= \term\; |\; val;pgm\; |\;data;pgm}\hfill \highlight{program}$\\
  $\highlight{val::=\mathit{\texttt{let }} \tmVar : \type = \term}\hfill \highlight{value binding}$\\
  $\highlight{datadecl::=\mathit{\texttt{data } T\; \tyVar = K \;\overline{\type}} }\hfill \highlight{datatype}$\\
  $\term ::= \tmVar\,|\,\lambda \tmVar:\type.\term\,|\,\term_1 \; \term_2 \,|\,\tyAbs{\tyVar}{\term}\,|\,\term\;\type \hfill term $\\
 $\phantom{aaa}|\;\highlight{K} \;|\;\highlight{\mathit{\texttt{let }} \tmVar : \type = \term \mathit{\texttt{ in}}} \;|\;\highlight{ \mathit{\texttt{case }} \term_1 \mathit{\texttt{ of }} K \; \overline{\tmVar} \rightarrow \term_2} $\\
  $\tmVal::= \lambda \tmVar:\type.\term \,|\,\tyAbs{\tyVar}{\term}\hfill value$\\
  $\type ::= \tyVar\,|\,\type \rightarrow \type \,|\,\forall \tyVar.\type\;|\; \highlight{T\;\type} \hfill type$\\
  $\tyEnv::=  empty \,|\, \tyEnv, \tmVar:\type\,|\, \tyEnv,\tyVar\;|\; \highlight{\tyEnv,K:\type}\;|\;\highlight{\tyEnv,T} \hfill environment$\\
  \caption{Syntax for the extended System F}
  \label{exsysfsyntax}
\end{figure}
\subsection{Typing}
We don't type declarations; as for programs, we give them the same type $\type$ we give their term  under the \textit{appropriate environment} $\tyEnv$.

The declarations present in the program before the term set the \textit{appropriate environment} under which the term is typed. Value bindings extend the environment in the obvious way: $\mathit{\texttt{let }} \tmVar : \type = \term$ adds to the environment that $\tmVar$ has type $\type$.

The datatype declaration $\mathit{\texttt{data } T\; \tyVar = K \;\overline{\type}}$, on the other hand, adds both the type constructor $T$; and the data constructor $K$ bound to its type. To construct a term of type $T\;\type_1$, first $\type_1$ and then $\overline{[\type_1/\tyVar]\overline{\type}}$ need to be applied to $K$.

As for the typing rules for terms in the extended System F's terms, there are two new rules: \textsc{T-Let} and \textsc{T-Case}. The former illustrates the recursive nature of our $\mathit{\texttt{let }} \tmVar : \type = \term_1 \mathit{\texttt{ in }\term_2}$: both $\term_1$ and $\term_2$ are typed in the extended environment in which $\tmVar$ is assumed to have type $\type$. This recursion allows us to write functions as the one in \ref{foldr}.

As for the \textsc{T-Case}, it states that a case expression $\mathit{\texttt{case }} \term_1 \mathit{\texttt{ of }} K \; \overline{\tmVar} \rightarrow \term_2$ has a type $\type_2$ if the branch ($\term_2$) has type $\type_2$ under the extended environment where the variables $\overline{\tmVar}$ are bound the corresponding types $\overline{\type}$, where the type variable $\tyVar$ has been substituted accordingly to the type of $\term_1$.

Both of these are highlighted in \fref{exsysftytm}.

\begin{figure}
  \includegraphics{exsysfty}
    \caption{Typing rules for the extended System F's terms}
  \label{exsysftytm}
\end{figure}

\subsection{Properties}
System F achieves what it set out to be: a type-safe language (well-typed terms either evaluate to a value or evaluate forever) which, by allowing parametric polymorphism, lifts unpleasant STLC's restrictions.

It would be convenient to drop System F's type annotations. However, that would cause the loss of the ability to, in general, type System F's terms.

In System F, the type variable $\tyVar$ in the type $\tyAbs{\tyVar}{\tyVar \rightarrow \tyVar}$ can refer to any System F type, including itself. The identity function has that type. We can apply any type to the identity function: $id\;(\tyAbs{\tyVar}{\tyVar \rightarrow \tyVar}$) is a perfectly valid System F term. Its type is then $(\tyAbs{\tyVar}{\tyVar \rightarrow \tyVar}) \rightarrow (\tyAbs{\tyVar}{\tyVar \rightarrow \tyVar})$. In cases like this, where the universal operator in a nested position of a more complex type $\type$, we call $\type$ a higher-rank type.

Without type annotations we would have to infer the types of System F's expressions. However, it has been proven that there is no algorithm capable of, in general, inferring the type of a language with higher-rank polymorphic types. In other words, type inference is undecidable for System F.

\subsection{An example}
Assuming we have declared the datatype $List$ with two data constructors, $[\,]$ and $Cons$, and a case allowing multiple branches (which we didn't for simplicity), we can now write the function foldl as shown in \fref{foldr}.

This is a well-known function in the context of functional programming. In languages with type inference, like Haskell, the type abstractions would be absent.
We can imagine the datatype declaration for the type constructor List to be:\\
$\mathit{\texttt{data } List\; \tyVar = [\;]\;\tyVar\;|\;Cons \;\tyVar\;(\mathit{List}\;\tyVar)}$\\

We can also consider a rule for case expressions with multiple branches. The case expression would then be well typed with type $\type_2$ if, for every branch $b$, we could infer from existing rule \textsc{T-Case} that the case with only branch $b$ has type $\type_2$.

We would then be able to use the typing rules to type $foldr$ has having type:\\
$\tyAbs{\tyVar_1}{\tyAbs{\tyVar_2}{((\tyVar_2 \rightarrow \tyVar_1 \rightarrow \tyVar_2)\rightarrow (\tyVar_2 \rightarrow (List\;\tyVar_1\rightarrow List\;\tyVar_2)))}}$.

\begin{figure}
  
  $foldr = \Lambda \tyVar_1 . \Lambda \tyVar_2 . \lambda \tmVar_1:\tyVar_2 \rightarrow \tyVar_1 \rightarrow \tyVar_2 . \lambda \tmVar_2 : \tyVar_2 . \lambda \tmVar_3 : List \, \tyVar_1 .$\\
  \phantom{foldl aaa}$\mathit{\texttt{case }} \tmVar_3 \mathit{\texttt{ of }}$\\
  \phantom{foldl aaaaa}$[\;] \phantom{ns a b iii}\rightarrow \tmVar_2$\\
  \phantom{foldl aaaaa}$Cons \; a \; b \rightarrow foldr \; \tyVar_1 \;\tyVar_2 \; \tmVar_1 \; (\tmVar_1 \; \tmVar_2 \; a)  \; b$
  
  
  \caption{Function $foldr$ in System F}
  \label{foldr}
\end{figure}


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "thesis"
%%% End: 
%evaluaEvaluation rules can now apply only to terms of a determined subset of the set of types. In particular, STLC leverages the partition of types into values and non-values in its evaluation rules. 
